{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZnNupTQvO9D3eTEW48qF6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thummavaishnavi/Machine-Learning/blob/main/ML_FaceDetectionUsingCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPdzfSSa8dTF",
        "outputId": "b694a03d-8e5c-4506-84cc-4745872256ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# configuring the path of Kaggle.json file\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AuJOiDV8qKh",
        "outputId": "1eba9dcc-a8d2-460b-a3f1-40bcaa5c5f83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Face Mask Dataset"
      ],
      "metadata": {
        "id": "Yqe5Q0-d8uvx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# API to fetch the dataset from Kaggle\n",
        "!kaggle datasets download -d omkargurav/face-mask-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIP0LZke8yKG",
        "outputId": "6fe07a32-a791-45a0-af22-2951ddc7d855"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/kaggle/api/kaggle_api_extended.py\", line 403, in authenticate\n",
            "    raise IOError('Could not find {}. Make sure it\\'s located in'\n",
            "OSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting the compessed Dataset\n",
        "from zipfile import ZipFile\n",
        "dataset = '/content/face-mask-dataset.zip'\n",
        "\n",
        "with ZipFile(dataset,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('The dataset is extracted')"
      ],
      "metadata": {
        "id": "2B7tZsL_83C9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "D7mg1dEu9Oyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing the Dependencies**"
      ],
      "metadata": {
        "id": "WUYzq4vE9RbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "8fNoOrkW9R6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with_mask_files = os.listdir('/content/data/with_mask')\n",
        "print(with_mask_files[0:5])\n",
        "print(with_mask_files[-5:])"
      ],
      "metadata": {
        "id": "zvv_sDN89VU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "without_mask_files = os.listdir('/content/data/without_mask')\n",
        "print(without_mask_files[0:5])\n",
        "print(without_mask_files[-5:])"
      ],
      "metadata": {
        "id": "U1AeikEr9XSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of with mask images:', len(with_mask_files))\n",
        "print('Number of without mask images:', len(without_mask_files))"
      ],
      "metadata": {
        "id": "_AMW8GKU9Zv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Labels for the two class of Images**"
      ],
      "metadata": {
        "id": "ObKblL9W9cyA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "with mask  -->  1\n",
        "\n",
        "without mask  -->  0"
      ],
      "metadata": {
        "id": "CSEAjPar9fwl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the labels\n",
        "\n",
        "with_mask_labels = [1]*3725\n",
        "\n",
        "without_mask_labels = [0]*3828"
      ],
      "metadata": {
        "id": "NBncB16B9dvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(with_mask_labels[0:5])\n",
        "\n",
        "print(without_mask_labels[0:5])"
      ],
      "metadata": {
        "id": "4fBPa6S39i4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(with_mask_labels))\n",
        "print(len(without_mask_labels))"
      ],
      "metadata": {
        "id": "qZe-2GyX9mnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = with_mask_labels + without_mask_labels\n",
        "\n",
        "print(len(labels))\n",
        "print(labels[0:5])\n",
        "print(labels[-5:])"
      ],
      "metadata": {
        "id": "0W3YI8-Z9oez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Displaying the Images**"
      ],
      "metadata": {
        "id": "rVZYzZy89icz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# displaying with mask image\n",
        "img = mpimg.imread('/content/data/with_mask/with_mask_1545.jpg')\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GfMd9GpH9tTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# displaying without mask image\n",
        "img = mpimg.imread('/content/data/without_mask/without_mask_2925.jpg')\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SkUqAoKs9yYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Image Processing**"
      ],
      "metadata": {
        "id": "jIFbEc-090cy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Resize the Images\n",
        "\n",
        "2. Convert the images to numpy arrays"
      ],
      "metadata": {
        "id": "uZGuuerJ926l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert images to numpy arrays\n",
        "\n",
        "with_mask_path = '/content/data/with_mask/'\n",
        "\n",
        "data = []\n",
        "\n",
        "# Iterate over all image files in the with_mask directory\n",
        "for img_file in with_mask_files:\n",
        "  # Open the image file\n",
        "  image = Image.open(with_mask_path + img_file)\n",
        "  # Resize the image to 128x128\n",
        "  image = image.resize((128,128))\n",
        "  # Convert the image to RGB format\n",
        "  image = image.convert('RGB')\n",
        "  # Convert the image to a NumPy array\n",
        "  image = np.array(image)\n",
        "  # Append the NumPy array to the data list\n",
        "  data.append(image)\n",
        "\n",
        "\n",
        "without_mask_path = '/content/data/without_mask/'\n",
        "\n",
        "\n",
        "for img_file in without_mask_files:\n",
        "# Iterate over all image files in the without_mask directory\n",
        "  image = Image.open(without_mask_path + img_file)\n",
        "  image = image.resize((128,128))\n",
        "  image = image.convert('RGB')\n",
        "  image = np.array(image)\n",
        "  data.append(image)"
      ],
      "metadata": {
        "id": "UJN0jBlk94-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(data)"
      ],
      "metadata": {
        "id": "HeLA8Q0O97Fp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "id": "5gQfkVSA99Rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "id": "9sBi9fxn9_Qd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(data[0])"
      ],
      "metadata": {
        "id": "134PapDw-BYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[0].shape"
      ],
      "metadata": {
        "id": "piX8varM-DdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting image list and label list to numpy arrays\n",
        "\n",
        "X = np.array(data)\n",
        "Y = np.array(labels)"
      ],
      "metadata": {
        "id": "0oHixHxN-Fuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(X)"
      ],
      "metadata": {
        "id": "03uAQ_56-Huo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(Y)"
      ],
      "metadata": {
        "id": "wQley8gM-Jar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "metadata": {
        "id": "_Hoibugl-LcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y)"
      ],
      "metadata": {
        "id": "hcbC6ysT-NfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train Test Split**"
      ],
      "metadata": {
        "id": "1GBBRNqi-Qce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)"
      ],
      "metadata": {
        "id": "kOcEVsm9-Sww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape, X_train.shape, X_test.shape)"
      ],
      "metadata": {
        "id": "3H4QynUI-Uki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scaling the data\n",
        "\n",
        "X_train_scaled = X_train/255\n",
        "\n",
        "X_test_scaled = X_test/255"
      ],
      "metadata": {
        "id": "Z_4_hNbY-WsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These lines of code are scaling the training and test data by dividing each pixel value by 255. This is a common practice in image processing to normalize the data and improve the performance of machine learning models."
      ],
      "metadata": {
        "id": "AjPYYxK2-ZOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0]"
      ],
      "metadata": {
        "id": "MA6uIc4r-cHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled[0]"
      ],
      "metadata": {
        "id": "srErg50O-eK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building a Convolutional Neural Networks (CNN)**"
      ],
      "metadata": {
        "id": "xCe1V0Wn-go_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "mDMbEVey-ipf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_of_classes = 2\n",
        "\n",
        "model = keras.Sequential()\n",
        "\n",
        "# First convolutional block\n",
        "model.add(keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(128,128,3)))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "\n",
        "model.add(keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(keras.layers.Flatten())\n",
        "\n",
        "model.add(keras.layers.Dense(128, activation='relu'))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "\n",
        "model.add(keras.layers.Dense(64, activation='relu'))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "\n",
        "\n",
        "model.add(keras.layers.Dense(num_of_classes, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "aFmtkx2s-kzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- num_of_classes: This variable specifies the number of classes that the model will predict. In this case, it is set to 2.\n",
        "- model: This variable stores the Keras model object.\n",
        "- keras.Sequential(): This creates a sequential model, where each layer is added sequentially.\n",
        "- model.add(keras.layers.Conv2D(...)): This adds a convolutional layer to the model.\n",
        "- 32: This specifies the number of filters in the convolutional layer.\n",
        "- kernel_size=(3,3): This specifies the size of the filter used in the convolution.\n",
        "- activation='relu': This specifies the activation function used in the convolutional layer.\n",
        "- input_shape=(128,128,3): This specifies the shape of the input images.\n",
        "- model.add(keras.layers.MaxPooling2D(...)): This adds a max pooling layer to the model.\n",
        "- pool_size=(2,2): This specifies the size of the pooling window.\n",
        "- model.add(keras.layers.Flatten()): This flattens the output of the previous layer into a single dimension\n",
        "- model.add(keras.layers.Dense(128, activation='relu')): This adds a dense layer with 128 units and ReLU activation.\n",
        "- model.add(keras.layers.Dropout(0.5)): This adds a dropout layer with a rate of 0.5, which means that 50% of the units in the previous layer will be randomly dropped during training.\n",
        "- model.add(keras.layers.Dense(64, activation='relu')): This adds another dense layer with 64 units and ReLU activation.\n",
        "- model.add(keras.layers.Dropout(0.5)): This adds another dropout layer with a rate of 0.5.\n",
        "- model.add(keras.layers.Dense(num_of_classes, activation='sigmoid')): This adds a final dense layer with a number of units equal to the number of classes and sigmoid activation."
      ],
      "metadata": {
        "id": "myWZkw8G-nfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the neural network\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['acc'])"
      ],
      "metadata": {
        "id": "026O8jPH-pjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training the neural network\n",
        "history = model.fit(X_train_scaled, Y_train, validation_split=0.1, epochs=5)"
      ],
      "metadata": {
        "id": "f0V9yirl-r1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Evaluation**"
      ],
      "metadata": {
        "id": "Ho77yTLr-yug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test_scaled, Y_test)\n",
        "print('Test Accuracy =', accuracy)"
      ],
      "metadata": {
        "id": "9bbJH7QV-wXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h = history\n",
        "\n",
        "# plot the loss value\n",
        "plt.plot(h.history['loss'], label='train loss')\n",
        "plt.plot(h.history['val_loss'], label='validation loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# plot the accuracy value\n",
        "plt.plot(h.history['acc'], label='train accuracy')\n",
        "plt.plot(h.history['val_acc'], label='validation accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2DFeibWF-0qX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predictive System**"
      ],
      "metadata": {
        "id": "S6FICgJB-3ZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_image_path = input('Path of the image to be predicted: ')\n",
        "\n",
        "input_image = cv2.imread(input_image_path)\n",
        "\n",
        "cv2_imshow(input_image)\n",
        "\n",
        "input_image_resized = cv2.resize(input_image, (128,128))\n",
        "\n",
        "input_image_scaled = input_image_resized/255\n",
        "\n",
        "input_image_reshaped = np.reshape(input_image_scaled, [1,128,128,3])\n",
        "\n",
        "input_prediction = model.predict(input_image_reshaped)\n",
        "\n",
        "print(input_prediction)\n",
        "\n",
        "\n",
        "input_pred_label = np.argmax(input_prediction)\n",
        "\n",
        "print(input_pred_label)\n",
        "\n",
        "\n",
        "if input_pred_label == 1:\n",
        "\n",
        "  print('The person in the image is wearing a mask')\n",
        "\n",
        "else:\n",
        "\n",
        "  print('The person in the image is not wearing a mask')"
      ],
      "metadata": {
        "id": "Mby9ub0R-5OI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_image_path = input('Path of the image to be predicted: ')\n",
        "\n",
        "input_image = cv2.imread(input_image_path)\n",
        "\n",
        "cv2_imshow(input_image)\n",
        "\n",
        "input_image_resized = cv2.resize(input_image, (128,128))\n",
        "\n",
        "input_image_scaled = input_image_resized/255\n",
        "\n",
        "input_image_reshaped = np.reshape(input_image_scaled, [1,128,128,3])\n",
        "\n",
        "input_prediction = model.predict(input_image_reshaped)\n",
        "\n",
        "print(input_prediction)\n",
        "\n",
        "\n",
        "input_pred_label = np.argmax(input_prediction)\n",
        "\n",
        "print(input_pred_label)\n",
        "\n",
        "\n",
        "if input_pred_label == 1:\n",
        "\n",
        "  print('The person in the image is wearing a mask')\n",
        "\n",
        "else:\n",
        "\n",
        "  print('The person in the image is not wearing a mask')"
      ],
      "metadata": {
        "id": "SEM75-hX-7Dx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}